# Core dependencies (Updated December 2025)
torch>=2.8.0
transformers>=4.57.0
sentencepiece>=0.2.0
tokenizers>=0.21.0  # Rust-based tokenizer
datasets>=4.4.0
accelerate>=1.0.0
safetensors>=0.7.0  # Rust-based tensor serialization
pyyaml>=6.0
tqdm>=4.66.0
numpy>=2.0.0
einops>=0.8.1
hf_transfer

# Rust-based fast packages
orjson>=3.10.0  # 10-50x faster JSON (Rust)
regex>=2024.0.0  # Rust-based regex, faster than re

# Fine-tuning dependencies
peft>=0.18.0
trl>=0.26.0
bitsandbytes>=0.45.0  # 8-bit Adam optimizer

# Training dependencies
deepspeed>=0.18.0
wandb>=0.23.0
tensorboard>=2.20.0

# Low-precision training (MXFP4/FP8)
# For PyTorch-native MXFP4/MXFP6/MXFP8 support
torchao>=0.11.0

# For NVIDIA GPU FP8/FP4 support (Hopper/Ada/Blackwell)
# Requires CUDA 12+ and compatible GPU
# Install with: pip install --no-build-isolation transformer_engine[pytorch]
# transformer-engine>=2.9.0

# Flash Attention (requires CUDA and specific installation)
# Install separately: pip install flash-attn --no-build-isolation
# flash-attn>=2.7.0

# Development dependencies
pytest>=9.0.0
black>=25.9.0
isort>=5.13.0
mypy>=1.13.0
jupyter>=1.1.0
