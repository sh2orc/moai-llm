"""
ë°ì´í„°ì…‹ ì •ë³´ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸

Usage:
    python check_dataset.py wikipedia
    python check_dataset.py allenai/c4
    python check_dataset.py BCCard/BCCard-Finance-Kor-QnA
"""

import argparse
from datasets import get_dataset_config_names, load_dataset_builder

def check_dataset(dataset_name: str):
    """ë°ì´í„°ì…‹ ì •ë³´ ì¶œë ¥"""

    print("="*80)
    print(f"Dataset: {dataset_name}")
    print("="*80)

    # 1. Config ëª©ë¡ í™•ì¸
    try:
        configs = get_dataset_config_names(dataset_name)
        if configs:
            print(f"\nðŸ“‹ Available Configs ({len(configs)} total):")
            print("-"*80)

            # í•œêµ­ì–´/ì˜ì–´ ê´€ë ¨ë§Œ í•„í„°ë§
            ko_configs = [c for c in configs if 'ko' in c.lower()]
            en_configs = [c for c in configs if 'en' in c.lower()]

            if ko_configs:
                print(f"Korean configs: {ko_configs[:5]}")
            if en_configs:
                print(f"English configs: {en_configs[:5]}")

            # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
            print(f"\nFirst 10 configs:")
            for i, config in enumerate(configs[:10]):
                print(f"  {i+1}. {config}")

            if len(configs) > 10:
                print(f"  ... and {len(configs) - 10} more")
        else:
            print("\nðŸ“‹ No config needed (use dataset_config=None)")

    except Exception as e:
        print(f"\nâš ï¸ Could not get configs: {e}")
        print("This dataset might not need a config.")

    # 2. ë°ì´í„°ì…‹ ì •ë³´
    try:
        builder = load_dataset_builder(dataset_name)
        print(f"\nðŸ“ Dataset Info:")
        print("-"*80)
        print(f"Description: {builder.info.description[:200]}...")

        if builder.info.features:
            print(f"\nðŸ”‘ Features (columns):")
            for name, feature in list(builder.info.features.items())[:5]:
                print(f"  - {name}: {feature}")

    except Exception as e:
        print(f"\nâš ï¸ Could not get dataset info: {e}")

    # 3. ì‚¬ìš© ì˜ˆì‹œ
    print(f"\nðŸ’¡ Usage Examples:")
    print("-"*80)

    if configs and len(configs) > 0:
        # Configê°€ ìžˆëŠ” ê²½ìš°
        example_config = ko_configs[0] if ko_configs else configs[0]

        print(f"# Tokenizer training")
        print(f"python train_tokenizer.py \\")
        print(f"    --dataset {dataset_name} \\")
        print(f"    --dataset_config {example_config} \\")
        print(f"    --output_dir tokenizers/")

        print(f"\n# Pretraining")
        print(f"python train.py \\")
        print(f"    --mode pretrain \\")
        print(f"    --dataset {dataset_name} \\")
        print(f"    --dataset_config {example_config} \\")
        print(f"    --output_dir outputs/pretrain")
    else:
        # Configê°€ ì—†ëŠ” ê²½ìš°
        print(f"# Tokenizer training (no config needed)")
        print(f"python train_tokenizer.py \\")
        print(f"    --dataset {dataset_name} \\")
        print(f"    --output_dir tokenizers/")

        print(f"\n# SFT (for Q&A datasets)")
        print(f"python train.py \\")
        print(f"    --mode sft \\")
        print(f"    --dataset {dataset_name} \\")
        print(f"    --pretrained_model outputs/pretrain/final_model \\")
        print(f"    --output_dir outputs/sft")

    print("="*80)


def main():
    parser = argparse.ArgumentParser(description="Check HuggingFace dataset info")
    parser.add_argument("dataset_name", type=str, help="Dataset name (e.g., wikipedia)")
    args = parser.parse_args()

    check_dataset(args.dataset_name)


if __name__ == "__main__":
    main()
